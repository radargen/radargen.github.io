<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="RadarGen: Project Page">
    <title>RadarGen: Automotive Radar Point Cloud Generation from Cameras</title>

    <!-- Google Fonts & Icons -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

    <!-- Custom Styles -->
    <link rel="stylesheet" href="static/css/styles.css">

    <!-- Scripts -->
    <script src="static/js/main.js" defer></script>
</head>

<body>

    <!-- Hero Section -->
    <section class="hero">
        <div class="container">
            <h1 class="title">RadarGen: Automotive Radar Point Cloud Generation from Cameras</h1>

            <div class="publication-venue">
                <span>Conference 202X</span>
            </div>

            <div class="authors">
                <span class="author-block"><a href="#">Author Name</a><sup>1</sup>,</span>
                <span class="author-block"><a href="#">Author Name</a><sup>2</sup>,</span>
                <span class="author-block"><a href="#">Author Name</a><sup>1</sup></span>
            </div>

            <div class="affiliations">
                <span class="author-block"><sup>1</sup>University Name</span>
                <span class="author-block"><sup>2</sup>Research Lab</span>
            </div>

            <div class="publication-links">
                <a href="#" class="link-btn">
                    <span class="icon"><i class="fas fa-file-pdf"></i></span>
                    <span>Paper</span>
                </a>
                <a href="#" class="link-btn">
                    <span class="icon"><i class="ai ai-arxiv"></i></span>
                    <span>arXiv</span>
                </a>
                <a href="#" class="link-btn">
                    <span class="icon"><i class="fab fa-youtube"></i></span>
                    <span>Video</span>
                </a>
                <a href="#" class="link-btn">
                    <span class="icon"><i class="fab fa-github"></i></span>
                    <span>Code</span>
                </a>
                <a href="#BibTeX" class="link-btn">
                    <span class="icon"><i class="fas fa-book"></i></span>
                    <span>BibTeX</span>
                </a>
            </div>
        </div>
    </section>

    <!-- Teaser Section -->
    <section class="container">
        <div class="paper-section">
            <div class="teaser-container">
                <!-- Replace with actual video/image -->
                <img src="static/images/teaser.gif" alt="Teaser" class="teaser-img">
            </div>
            <div class="text-center" style="margin-top: 24px;">
                <p style="font-size: 1.25rem; font-weight: 600; margin-bottom: 12px;">
                    TL;DR: <span class="sc">RadarGen</span> generates sparse radar point clouds from multi-view camera
                    images.
                </p>
                <p style="color: var(--text-secondary); max-width: 800px; margin: 0 auto;">
                    The animation above shows the generation process. Input camera images (left) are transformed into
                    realistic 3D radar point clouds (right), preserving scene geometry and handling occlusions.
                </p>
            </div>
        </div>
    </section>

    <!-- Abstract Section -->
    <section class="container">
        <div class="paper-section">
            <div class="section-title">Abstract</div>
            <div class="abstract-content">
                <p>
                    We present <span class="sc">RadarGen</span>, a diffusion model for synthesizing realistic automotive
                    radar point clouds from multi-view camera imagery.
                    <span class="sc">RadarGen</span> adapts efficient image-latent diffusion to the radar domain by
                    representing radar measurements in birdâ€™s-eye-view form that encodes spatial structure together with
                    radar cross
                    section (RCS) and Doppler attributes.
                    A lightweight recovery step reconstructs point clouds from the generated maps.
                    To better align generation with the visual scene, <span class="sc">RadarGen</span> incorporates
                    BEV-aligned depth, semantic, and motion cues extracted from pretrained foundation models, which
                    guide the stochastic generation
                    process toward physically plausible radar patterns.
                    Conditioning on images makes the approach broadly compatible, in principle, with existing visual
                    datasets and simulation frameworks, offering a scalable direction for multimodal generative
                    simulation.
                    Evaluations on large-scale driving data show that <span class="sc">RadarGen</span> captures
                    characteristic radar measurement
                    distributions and reduces the gap to perception models trained on real data, marking a step toward
                    unified generative simulation across sensing modalities.
                </p>
            </div>
        </div>
    </section>

    <!-- Method Section -->
    <section class="container">
        <div class="paper-section">
            <div class="section-title">Method</div>

            <!-- Method Slider -->
            <div class="slider-container">
                <div class="slides-wrapper">

                    <!-- Slide 1 -->
                    <div class="slide">
                        <div class="slide-content-wrapper">
                            <h3 class="method-title">1. Representing radar as images</h3>
                            <div class="slider-image-container">
                                <img src="static/images/RadarGen_Method_1.png" alt="View Transformation"
                                    class="slider-img">
                            </div>
                            <p class="method-text">
                                The image features are then transformed into a bird's-eye-view (BEV) representation.
                                This aligns the camera data with the native coordinate system of automotive radar
                                sensors.
                            </p>
                        </div>
                    </div>

                    <!-- Slide 2 -->
                    <div class="slide">
                        <div class="slide-content-wrapper">
                            <h3 class="method-title">2. BEV Scene Conditioning</h3>
                            <div class="slider-image-container">
                                <img src="static/images/RadarGen_Method_2.png" alt="BEV Scene Conditioning"
                                    class="slider-img">
                            </div>
                            <p class="method-text">
                                We begin by extracting multi-scale features from the input camera images using a
                                pre-trained backbone.
                                This allows us to capture both semantic and geometric cues essential for radar
                                synthesis.
                            </p>
                        </div>
                    </div>

                    <!-- Slide 3 (Shared Image Left) -->
                    <div class="slide">
                        <div class="slide-content-wrapper">
                            <h3 class="method-title">3. Conditional Radar Maps Denoising</h3>
                            <!-- Use img-crop-container logic -->
                            <div class="slider-image-container img-crop-container">
                                <img src="static/images/RadarGen_Method_3_4.png" alt="Diffusion Process"
                                    class="slider-img img-pos-left">
                            </div>
                            <p class="method-text">
                                A latent diffusion model conditionally generates the radar BEV distribution.
                                It iteratively denoises the latent map, guided by the condition derived from the visual
                                features.
                            </p>
                        </div>
                    </div>

                    <!-- Slide 4 (Shared Image Right) -->
                    <div class="slide">
                        <div class="slide-content-wrapper">
                            <h3 class="method-title">4. Recovering Radar PCL</h3>
                            <div class="slider-image-container img-crop-container">
                                <!-- Helper class 'img-pos-right' focuses on right side -->
                                <img src="static/images/RadarGen_Method_3_4.png" alt="Point Recovery"
                                    class="slider-img img-pos-right">
                            </div>
                            <p class="method-text">
                                Finally, the generated dense radar map is decoded and sampled to produce the sparse 3D
                                point cloud,
                                complete with Doppler velocity and RCS information.
                            </p>
                        </div>
                    </div>

                </div>

                <!-- Controls -->
                <div class="slider-controls">
                    <button class="control-btn btn-prev"><i class="fas fa-chevron-left"></i></button>
                    <button class="control-btn btn-pause"><i class="fas fa-pause"></i></button>
                    <button class="control-btn btn-next"><i class="fas fa-chevron-right"></i></button>
                </div>

                <!-- Progress Bar -->
                <div class="progress-container">
                    <div class="progress-bar"></div>
                </div>

                <div class="slider-pagination">
                    <button class="nav-btn active" data-slide="0">1. Representing radar as images</button>
                    <button class="nav-btn" data-slide="1">2. BEV Scene Conditioning</button>
                    <button class="nav-btn" data-slide="2">3. Conditional Radar Maps Denoising</button>
                    <button class="nav-btn" data-slide="3">4. Recovering Radar PCL</button>
                </div>
            </div>

        </div>
    </section>

    <!-- Results Section -->
    <!-- Video Section -->
    <section class="container">
        <div class="paper-section">
            <div class="section-title">Video</div>
            <div class="teaser-container">
                <!-- <video class="teaser-video" controls autoplay muted loop playsinline> -->
                <video class="teaser-video" controls muted playsinline>
                    <source src="static/images/RadarGen Video.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
            </div>
        </div>
    </section>

    <!-- Qualitative Comparison Section -->
    <section class="container">
        <div class="paper-section">
            <div class="section-title">Qualitative Comparison</div>
            <div class="teaser-container">
                <img src="static/images/RadarGen_comparison.png"
                    alt="Qualitative Comparison: Input vs Baseline vs Ours vs Real" class="teaser-img">
            </div>
            <p class="text-center" style="color: var(--text-secondary); margin-top: 15px;">
                Comparisons demonstrate that our method captures details missed by the baseline, closely matching the
                ground truth.
            </p>
        </div>
    </section>

    <!-- Scene Editing Section -->
    <section class="container">
        <div class="paper-section">
            <div class="section-title">Scene Editing</div>
            <div class="teaser-container">
                <img src="static/images/RadarGen_Scene_Editing.png"
                    alt="Controllable Generation: Edited Input to New Radar" class="teaser-img">
            </div>
            <p class="text-center" style="color: var(--text-secondary); margin-top: 15px;">
                We can generate novel radar scenes by simply editing the input images (e.g., adding or removing
                vehicles).
            </p>
        </div>
    </section>

    <!-- BibTeX Section -->
    <section class="container" id="BibTeX">
        <div class="paper-section">
            <div class="section-title">BibTeX</div>
            <div class="bibtex-wrapper">
                <button class="copy-btn" id="copyBibtexBtn">
                    <i class="fas fa-copy"></i> Copy
                </button>
                <pre class="bibtex-container" id="bibtexCode"><code>@article{abc2025method,
  author    = {Author, Name and Author, Name},
  title     = {RadarGen: Automotive Radar Point Cloud Generation from Cameras},
  journal   = {Conference},
  year      = {202X},
}</code></pre>
            </div>
        </div>
    </section>

    <footer>
        <div class="container">
            <div style="display: inline-block; text-align: left; max-width: 710px;">
                <p style="margin-bottom: 10px;">
                    This website is licensed under a <a rel="license"
                        href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike
                        4.0
                        International License</a>.
                </p>
                <p style="margin-bottom: 3px;">
                    The source code for this website is available for use and modification. If you choose to use it,
                    attribution via a link back to this website is required.
                </p>
                <p style="font-size: 0.85rem; opacity: 0.7; margin-bottom: 0;">
                    Note: Remove all tracking and analytics identifiers from the code prior to deployment.
                </p>
            </div>
        </div>
    </footer>

</body>

</html>